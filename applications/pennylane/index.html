<!DOCTYPE html>
<!--  URA application -->
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Applications</title>
    <link rel="stylesheet" href="../style.css">
    <script src="../script.js" defer></script>
</head>
<body>
    <nav class = "header-bar">
        <a href="/" class="nav-link">Home</a>
        <a href="../" class="nav-link">Applications</a>
        <button id = "theme-toggle" aria-label="Activate Dark Mode">üåì</button>
    </nav>
    <div id="content">
        <h1 class = "center-header">Benchmarking a Hybrid Quantum-Classical classifier with PennyLane and MLflow.</h1>
        <div>
            <div>
                <span>Joshua Choong</span> 
                <span>February 13</span> 
            </div>
            <div>
                <img src="./assets/hybrid-model.png" alt="Hybrid Model">
            </div>
                final accuracy scores
        </div>
        <h2>Introduction:</h2>
        <p>
            The overall goal with this project was to experiment with implementing a Quantum-Classical hybrid ML classifier,
            and to get familiar with the PennyLane Python library, as well as learning professional practices for benchmarking 
            machine learning classifiers.
        </p>
        <p>
            I implemented a hybrid Quantum-Classical machine learning classifier, using a variational quantum circuit in combination with a 
            classical linear layer. The trained hybrid-model scored 78.9% accuracy on unseen data, indicating a successful implementation and a baseline to iterate further upon.
            Through ablation study analysis, it was determined that the inclusion of quantum parameters in combination with a classical layer resulted in a 7% increase in accuracy
            over the exclusive latter classifier. This suggests that our gradients were successfully propagating through the quantum circuit, and that our ansatz circuit was 
            learning task-relevant features. 
            In addition, analysis of the observations in this study revealed an interesting revelation: hybrid Quantum-Classical models can make progress through otherwise 
            impassable plateaus. This is talked about more in detail in <a href="#pennyLaneSection3"> section 4 </a>
        </p>
        <img src="./assets/UpdatedTitle.png" alt="quantum vs frozen ablation study">
        <p>
            I learned a lot about the fascinating field of Quantum Computing, as well as how to responsibly implement experiment tracking and reproducibility through MLflow. 
            Steps for future development would include analyzing circuit design to add expressivity, and researching which datasets are especially applicable for hybrid-quantum classifiers.
        </p>

        <h2>Contents:</h2>
        <ul>
            <li>
                <a href ="#pennyLaneSection1">
                    1. Baseline Model - Classical Logistic Regression</li> 
                </a>
            <li>
                <a href = "#pennyLaneSection2">
                    2. Quantum Circuits with PennyLane
                </a>
            </li> 
            <li>
                <a href = "#pennyLaneSection3">
                    3. Hybrid Quantum-Classical Model 
                </a>
            </li> 
            <li>
                <a href = "#pennyLaneSection4">
                    4. Results
                </a>
            </li> 
        </ul>
        
        <h2 id = "pennyLaneSection1">1. Baseline Model - Classical Logistic Regression</h2>
        <p>
            I started by utilizing the scikit-learn logistic regression classifier on the  
            <a href="https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic.">Wisconsin Breast Cancer Dataset</a>.
            This yielded an impressive accuracy of 96%, serving as a solid baseline for comparison.
        </p>
        Loading breast cancer dataset from scikit-learn
        <pre class="code-block">
    <code>
bc = load_breast_cancer()
X = bc.data
y = bc.target
    </code>
        </pre>
        Separating Data into training/test validation, using random seed 42
        <pre class="code-block"><code>from sklearn.model_selection import train_test_split
    from sklearn.decomposition import PCA
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    </code></pre>
        Feature extraction with PCA for logistic regression
        <pre class="code-block"><code>n_qubits = 4
    pca = PCA(n_components=n_qubits)
    X_train_q = pca.fit_transform(X_train)
    X_test_q = pca.transform(X_test)
    </code></pre>
        Applying Logistic regression model to data
        <pre class="code-block"><code>from sklearn.linear_model import LogisticRegression
    clf = LogisticRegression(solver="lbfgs")
    clf.fit(X_train_q, y_train)
    y_pred = clf.predict(X_test_q)
    acc = accuracy_score(y_test, y_pred)
    </code></pre>
        <p>
            It is worth noting that this dataset is an especially ideal application for Logistic Regression.
            With a feature set that is remarkably linearly separable, logistic regression excels at 
            finding a linear decision boundary with high accuracy. In addition, since false negatives
            would be unacceptable in this serious setting, utilizing a threshold activation function over a binary classifier
            provides a much-needed confidence interval.  
        </p>

        <h2 id="pennyLaneSection2">2. Quantum Circuits with PennyLane</h2>
        <p>
            This is where the majority of my experimentation and learning took place. 
            If you are unfamiliar with Quantum Computing, I would recommend checking out this excellent <a href="https://quantum.country/qcvc">resource</a> for an introduction.
        </p>
        <img src="assets/quantumCircuit.png" alt="quantum ansatz diagram">
        <p>
            This quantum circuit is a simplistic implementation of an ansatz using PennyLane's <a href="https://docs.pennylane.ai/en/stable/introduction/circuits.html">QNode function</a> with 4 wires (4 qubits).
            PennyLane has several excellent articles on ansatz creation; I found this one on <a href="https://pennylane.ai/qml/demos/tutorial_rotoselect">Quantum circuit structure learning</a> particularly insightful.
        </p>

        <p>
            Each wire begins with feature encoding through a single qubit rotation gates: around the x axis in the Bloch sphere, by the angle X[i], which determines the rotation angle.
            So essentially, our input value x is encoded into a quantum state, where each input represents a rotation angle. 
        </p>
        <p>
            We then add variational layers. For each layer, we do two steps:
            <ol>
                <li>
                    First, each wire is rotated around the y axis with a trainable parameter. In this way, we are able to create a feature space, where rotation angles are weights.
                </li>
                <li>
                    Next, we create a "ladder" of CNOT gates. This allows us to create a sequence of quantum entanglement, which allows us to 
                    represent correlation between input features 
                </li>
            </ol>
        </p>
        <p>
            Finally, at the end of each wire we have a measurement gate, which allows us to return the expected value of PauliZ on each qubit.
            This vector can be interpreted as the quantum feature range of continuous expected values ([-1,1]), which we can then use 
            in the calculation of our loss function. This process is detailed more in <a href="#pennyLaneSection3">section 3</a>.
        </p>
        <p>
            Use Principal Component Analysis to reduce the 30-dimensional feature set through feature extraction to 4 dimensions for the quantum classifier
        </p>
        <pre class="code-block"><code>import pennylane as qml
    from pennylane import numpy as np

    n_qubits = 4
    pca_q = PCA(n_components=n_qubits)
    X_train_q = pca_q.fit_transform(X_train)
    X_test_q = pca_q.transform(X_test)
    </code></pre>
        Applying l2 feature regularization after PCA so angles aren't absurdly large
        <pre class="code-block"><code>scaler = StandardScaler()
    X_train_q = scaler.fit_transform(X_train_q)
    X_test_q = scaler.transform(X_test_q)

    # Labels stay as {0, 1} for sigmoid/BCE
    y_train_q = y_train
    y_test_q = y_test
    </code></pre>
        Quantum device and differentiable circuit
        <pre class="code-block">
            <code>
dev = qml.device("lightning.qubit", wires=n_qubits)
@qml.qnode(dev, interface="autograd")
def qnode(x, weights):
    # Feature encoding
    for i in range(n_qubits):
        qml.RX(x[i], wires=i)

    # Variational layers
    for l in range(weights.shape[0]):
        for i in range(n_qubits):
            qml.RY(weights[l, i], wires=i)
        for i in range(n_qubits - 1):
            qml.CNOT(wires=[i, i + 1])

    # Return vector of expectation values (quantum feature vector)
    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]
            </code>
        </pre>

        <h2 id = "pennyLaneSection3">3. Hybrid Quantum-Classical Model</h2>

        <h3> Training setup</h3>
        <div>
            <p>
                The hybrid model combines a parameterized quantum circuit with a classical linear layer.
                The quantum circuit acts as a nonlinear feature extractor, while the classical layer performs
                logistic classification on the resulting quantum feature vector. 
            </p>   
            <p>
                Essentially, our workflow is:
                <ul>
                    <li> <strong> Data Preprocessing: </strong>
                        <ul>
                            <li>Load Wisconsin Breast Cancer dataset from scikit-learn </li>
                            <li>Perform Principal Component Analysis with SVD to extract 4 features</li>
                            <li>Apply StandardScaler normalization, improving gradient descent performance </li>
                        </ul>
                    </li>
                    <li> <strong>Model Initialization</strong>
                        <ul>
                            <li>Initialize quantum weights with 4 qubits and 5 layers</li>
                            <li>Initialize classical weights with 4 parameters</li>
                        </ul>
                    </li>
                    <li><strong>Training Loop (300 epochs):</strong>
                        <ol>
                            <li><strong>Forward Pass:</strong> For each input x:
                                <ul>
                                    <li>Encode features via RX gates: x ‚Üí |œà(x)‚ü©</li>
                                    <li>Apply variational layers (RY rotations + CNOT entanglement)</li>
                                    <li>Measure expectation values: z = [‚ü®Z‚ÇÄ‚ü©, ‚ü®Z‚ÇÅ‚ü©, ‚ü®Z‚ÇÇ‚ü©, ‚ü®Z‚ÇÉ‚ü©] ‚àà [-1,1]‚Å¥</li>
                                    <li>Compute logit via dot product: logit = w * z</li>
                                    <li>predict values via sigmoid activation function: p = sigmoid(logit) ‚àà (0,1)</li>
                                </ul>
                            </li>
                            <li><strong>Compute Loss:</strong> Binary cross-entropy between predictions and labels</li>
                            <li><strong>Backward Pass:</strong> Compute gradients via parameter-shift rule (quantum) and autodiff (classical)</li>
                            <li><strong>Update Weights:</strong> The Adam-optimizer updates both quantum and classical weights jointly based on gradients</li>
                        </ol>
                    </li>
                    <li><strong>Evaluation:</strong> Threshold probabilities at 0.5 for final classification</li>
                </ul>
            </p>
            <p>
                We selected <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.AdamOptimizer.html">AdamOptimizer</a> as our optimizer to employ gradient based training for both quantum and classical parameters.
                While quantum natural gradients are theoretically optimal in accordance with the Fubini‚ÄìStudy geometry, our selection of the Adam-optimizer
                is sufficient as a "strong baseline for variational quantum algorithms" <a href="https://arxiv.org/abs/2012.09265">Cerezo et al. (2021) Variational Quantum Algorithms. arXiv. https://arxiv.org/abs/2012.09265</a>
                An extension of this project could involve implementing natural gradients, allowing for a higher computational complexity and Quantum circuit design.
            </p>
        </div>

        

        <div>
            <p>
            For each input sample, the QNode returns a vector of expectation values:
            </p>
            <pre class="code-block"><code># Example output from qnode
z = qnode(x, weights)  # shape: (n_qubits,)
</code></pre>
    
            <p>
            These expectation values lie in the range [-1, 1] and serve as learned quantum features.
            A classical weight vector is then applied:
            </p>
    
            <pre class="code-block"><code>def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def hybrid_model(x, weights, classical_weights):
    z = qnode(x, weights)
    logit = np.dot(classical_weights, z)
    return sigmoid(logit)
</code></pre>
    
            <p>
            The model is trained using binary cross-entropy loss:
            </p>
    
            <pre class="code-block"><code>def binary_cross_entropy(y_true, y_pred):
    eps = 1e-8
    return -np.mean(
        y_true * np.log(y_pred + eps) +
        (1 - y_true) * np.log(1 - y_pred + eps)
    )
</code></pre>
    
            <p>
            Both the quantum circuit parameters and classical weights are optimized jointly using gradient descent.
            MLflow is used to track hyperparameters, seeds, and evaluation metrics for reproducibility.
            </p>
        </div>

        <h2 id = "pennyLaneSection4">4. Results</h2>
        
        <img src = "./assets/vqcAnalysized.png" alt = "comparison of quantum vs classical weights">
        <p>
        Interpreting these results, we can see our model successfully implemented a hybrid quantum-classical classifier. It scored 82% on training data, and generalized to 78.9% on unseen data.
        Both weights trended towards a high L2 score, suggesting that the model was utilizing both weights equally.
        This is exemplified by an ablation analysis that revealed a plateau for classical weights when combined with frozen quantum weights
        </p>
        <img src = "./assets/GoldCropped.png" alt ="interesting correlation">
        <p>
            Interestingly, the ablation accuracy with exclusive classical weights and frozen quantum weights plateaued at 72%. This 7% increase suggests that a 
            hybrid quantum-classical ML classifier may excel in nonlinear datasets, effectively acting as a "pseudo-SVM" and revealing perhaps otherwise unnoticeable data.
        </p>

        <p>
        Hybrid QML models introduce nonlinear structure through quantum feature maps.
        However, when the dataset is already well described by a linear decision boundary,
        additional model complexity does not necessarily improve performance. So while this did not surpass the classical baseline of logistic regression (96.4%), the result is not surprising given that the
        breast cancer dataset is nearly linearly separable and therefore highly favorable to logistic regression.
        </p>

        <h3>Discussion</h3>

        <p>
        Although the hybrid model underperformed relative to logistic regression,
        the primary objective of this project was not to demonstrate quantum advantage,
        but to prototype and benchmark hybrid workflows in a reproducible manner.
        </p>

        <p>
        Key takeaways include:
        </p>

        <ul>
            <li>Implementing differentiable QNodes in PennyLane</li>
            <li>Integrating quantum circuits into classical ML pipelines</li>
            <li>Using MLflow for experiment tracking and reproducibility</li>
            <li>Comparing hybrid models against appropriate classical baselines</li>
        </ul>

        <p>
        Future work could include:
        </p>

        <ul>
            <li>Evaluating deeper circuits</li>
            <li>Testing sensitivity to initialization and random seeds</li>
            <li>Implementing QNG to correct for equilateral treatment of parameters</li>
            <li>Benchmarking on datasets with stronger nonlinear structure</li>
        </ul>

        <h2>Conclusion</h2>
        <p>
        This project demonstrates a complete hybrid quantum-classical ML workflow using PennyLane,
        including reproducible benchmarking against classical baselines.
        While the hybrid model did not outperform logistic regression on this dataset,
        the implementation provides a solid foundation for systematic experimentation
        with variational circuits and hybrid learning pipelines.
        </p>
        <p>
        This blog highlights the importance of dataset selection, as the Wisconsin Breast Cancer dataset is highly linearly separable, and our 
        current implementation did not provide an advantage over logistic regression.
        Creating carefully designed applications of quantum computing for machine learning classifiers is paramount.
        </p>


        <p>
        All code, experiment logs, and configuration details are available in the accompanying <a href="https://github.com/JoshhChoong/PennyLaneHybridQuantumClassicClassifier">GitHub repository</a>.
        </p>
    </div>
</body>
</html>